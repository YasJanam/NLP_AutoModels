{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "| لایه / کامپوننت                             | نوع ماژول                      | توضیح کوتاه                          |\n",
        "| ------------------------------------------- | ------------------------------ | ------------------------------------ |\n",
        "| model                                       | BartModel                      | مدل اصلی BART شامل encoder و decoder |\n",
        "| model.shared                                | BartScaledWordEmbedding        | embedding مشترک                      |\n",
        "| **model.encoder**                               | BartEncoder                    | انکودر مدل                           |\n",
        "| model.encoder.embed\\_tokens                 | BartScaledWordEmbedding        | embedding ورودی انکودر               |\n",
        "| model.encoder.embed\\_positions              | BartLearnedPositionalEmbedding | embedding موقعیتی                    |\n",
        "| model.encoder.layers                        | ModuleList                     | لیست لایه‌های انکودر                 |\n",
        "| model.encoder.layers.{i}                    | BartEncoderLayer               | لایه انکودر (i=0-11)                 |\n",
        "| model.encoder.layers.{i}.self\\_attn         | BartAttention                  | self-attention                       |\n",
        "| model.encoder.layers.{i}.fc1                | Linear                         | لایه اول feed-forward                |\n",
        "| model.encoder.layers.{i}.fc2                | Linear                         | لایه دوم feed-forward                |\n",
        "| model.encoder.layers.{i}.final\\_layer\\_norm | LayerNorm                      | نرمالیزاسیون نهایی                   |\n",
        "| model.encoder.layernorm\\_embedding          | LayerNorm                      | نرمالیزاسیون embedding               |\n",
        "| **model.decoder**                               | BartDecoder                    | دیکودر مدل                           |\n",
        "| model.decoder.embed\\_tokens                 | BartScaledWordEmbedding        | embedding ورودی دیکودر               |\n",
        "| model.decoder.embed\\_positions              | BartLearnedPositionalEmbedding | embedding موقعیتی                    |\n",
        "| model.decoder.layers                        | ModuleList                     | لیست لایه‌های دیکودر                 |\n",
        "| model.decoder.layers.{j}                    | BartDecoderLayer               | لایه دیکودر (j=0-11)                 |\n",
        "| model.decoder.layers.{j}.self\\_attn         | BartAttention                  | self-attention                       |\n",
        "| model.decoder.layers.{j}.encoder\\_attn      | BartAttention                  | encoder-decoder attention            |\n",
        "| model.decoder.layers.{j}.fc1                | Linear                         | لایه اول feed-forward                |\n",
        "| model.decoder.layers.{j}.fc2                | Linear                         | لایه دوم feed-forward                |\n",
        "| model.decoder.layers.{j}.final\\_layer\\_norm | LayerNorm                      | نرمالیزاسیون نهایی                   |\n",
        "| model.decoder.layernorm\\_embedding          | LayerNorm                      | نرمالیزاسیون embedding               |\n",
        "| lm\\_head                                    | Linear                         | لایه خروجی logits                    |\n"
      ],
      "metadata": {
        "id": "THqPsATxFS34"
      }
    }
  ]
}