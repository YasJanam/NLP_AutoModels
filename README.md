# NLP_AutoModels

---
### AutoModel-Types

| AutoModel-Type                         | Model-Type                | Ú©Ø§Ø±Ø¨Ø±Ø¯ Ú©Ù„ÛŒ           | Trainer        | Task                                                   | Models                                              |
| -------------------------------------- | ------------------------- | -------------------- | -------------- | ------------------------------------------------------ | --------------------------------------------------- |
| **AutoModelForSequenceClassification** | ğŸ”µ Encoder-Only (BERT-like)  |  Ø¯Ø±Ú© Ù…ØªÙ†   | Trainer        | Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙ† (sentiment analysisØŒ Ù…ÙˆØ¶ÙˆØ¹â€ŒÛŒØ§Ø¨ÛŒ)         | Encoder Models (BERT, RoBERTa, DistilBERT, Electra) |
| **AutoModelForTokenClassification**    | ğŸ”µ Encoder-Only (BERT-like)  |  Ø¯Ø±Ú© Ù…ØªÙ†   | Trainer        | Ø¨Ø±Ú†Ø³Ø¨â€ŒØ²Ù†ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ (NERØŒ POS tagging)                   | BERT, RoBERTa, XLM-R                                |
| **AutoModelForQuestionAnswering**      | ğŸ”µ Encoder-Only (BERT-like)  |  Ø¯Ø±Ú© Ù…ØªÙ†   | Trainer        | Ù¾Ø±Ø³Ø´â€ŒÙ¾Ø§Ø³Ø® Ø§Ø³ØªØ®Ø±Ø§Ø¬ÛŒ (Ø¬ÙˆØ§Ø¨ Ø§Ø² Ø¯Ù„ Ù…ØªÙ†)                    | BERT, RoBERTa, DistilBERT, ALBERT                   |
| **AutoModelForMaskedLM**               | ğŸ”µ Encoder-Only (BERT-like)  |  Ø¯Ø±Ú© Ù…ØªÙ†   | Trainer        | Ø²Ø¨Ø§Ù†â€ŒÙ…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÙˆØ´ÛŒØ¯Ù‡ (Ù¾Ø±Ú©Ø±Ø¯Ù† Ø¬Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ)               | BERT, RoBERTa, DistilBERT                           |
| **AutoModelForCausalLM**               | ğŸ”´ **Decoder-Only** (GPT-like)   |  **ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†** | Trainer        | ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¨Ù‡ Ø³Ø¨Ú© GPT (Ø²Ø¨Ø§Ù†â€ŒÙ…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù„ÛŒ)               | GPT-2, GPT-Neo, GPT-J, LLaMA, Falcon                |
| **AutoModelForSeq2SeqLM**              | ğŸŸ¢ **Encoder-Decoder** (Seq2Seq) | **Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ØªÙ†**        | **Seq2SeqTrainer** | Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Encoder-Decoder (ØªØ±Ø¬Ù…Ù‡ØŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†) | T5, BART, mBART, MarianMT, Pegasus                  |


---

| Ù…Ø¹Ù…Ø§Ø±ÛŒ                        | Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§                     | Ù†Ú¯Ø§Ù‡ Ø¨Ù‡ Ù…ØªÙ†                         | Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø§ØµÙ„ÛŒ                                     |
| ----------------------------- | --------------------------- | ----------------------------------- | ----------------------------------------------- |
| **Encoder-only**              | BERT, RoBERTa               | Ú©Ù„ Ù…ØªÙ† (Ø¯ÙˆØ·Ø±ÙÙ‡ØŒ bidirectional)      | Ø¯Ø±Ú© Ù…ØªÙ† (classification, NER, QA extractive)    |
| **Decoder-only (CausalLM)**   | GPT-2, GPT-3, LLaMA, Falcon | ÙÙ‚Ø· Ú¯Ø°Ø´ØªÙ‡ (Ú†Ù¾ Ø¨Ù‡ Ø±Ø§Ø³Øª)              | ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† (text generation, completion)         |
| **Encoder-Decoder (Seq2Seq)** | T5, BART, MarianMT, Pegasus | Encoder â†’ Ú©Ù„ Ù…ØªÙ†   / Decoder â†’ causal | Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ØªÙ† (translation, summarization, etc.) |

---
